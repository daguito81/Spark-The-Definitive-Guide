{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dataframe Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import SparkSession, Row\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql.types import StructField, StructType, StringType, LongType"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession\\\n",
    "    .builder\\\n",
    "    .master(\"local[*]\")\\\n",
    "    .appName(\"Test App\")\\\n",
    "    .getOrCreate()\n",
    "spark.catalog.clearCache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://31c215c47002:4040\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.0.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>Test App</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7fc0196998e0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "manual_schema = StructType([\n",
    "    StructField(\"some\", StringType(), True),\n",
    "    StructField(\"column\", StringType(), True),\n",
    "    StructField(\"names\", LongType(), True)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_row = Row(\"Hello\", \"World\", 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_df = spark.createDataFrame([my_row], schema=manual_schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----+------+-----+\n",
      "| some|column|names|\n",
      "+-----+------+-----+\n",
      "|Hello| World|   42|\n",
      "+-----+------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "my_df.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = spark.read\\\n",
    "    .format(\"csv\")\\\n",
    "    .option(\"inferSchema\", True)\\\n",
    "    .option(\"header\", True)\\\n",
    "    .load(\"../../data/flight-data/csv/*.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Operations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Select"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+\n",
      "|DEST_COUNTRY_NAME|\n",
      "+-----------------+\n",
      "|    United States|\n",
      "|    United States|\n",
      "+-----------------+\n",
      "only showing top 2 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"DEST_COUNTRY_NAME\").show(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|\n",
      "+-----------------+-------------------+\n",
      "|    United States|            Romania|\n",
      "|    United States|            Ireland|\n",
      "|    United States|              India|\n",
      "+-----------------+-------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"DEST_COUNTRY_NAME\", \"ORIGIN_COUNTRY_NAME\").show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+\n",
      "|  DESTINATION| ORIGIN|\n",
      "+-------------+-------+\n",
      "|United States|Romania|\n",
      "|United States|Ireland|\n",
      "|United States|  India|\n",
      "+-------------+-------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(F.expr(\"DEST_COUNTRY_NAME AS DESTINATION\"), F.expr(\"ORIGIN_COUNTRY_NAME AS ORIGIN\")).show(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: int, LOCAL_FLIGHT: boolean, MULTI_FLIGHT: int]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.selectExpr(\"*\", \"(DEST_COUNTRY_NAME = ORIGIN_COUNTRY_NAME) AS LOCAL_FLIGHT\", \"(count * 10) AS MULTI_FLIGHT\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+------------------+----------+----------+-----------------------------------+\n",
      "|        avg(count)|max(count)|min(count)|count(DISTINCT ORIGIN_COUNTRY_NAME)|\n",
      "+------------------+----------+----------+-----------------------------------+\n",
      "|1718.3189081225032|    370002|         1|                                154|\n",
      "+------------------+----------+----------+-----------------------------------+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"AVG(count)\", \"MAX(count)\", \"MIN(count)\", \"COUNT(DISTINCT ORIGIN_COUNTRY_NAME)\").show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Renaming Colums"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------+-------+-------+\n",
      "|         DEST| ORIGIN|FLIGHTS|\n",
      "+-------------+-------+-------+\n",
      "|United States|Romania|      1|\n",
      "|United States|Ireland|    264|\n",
      "|United States|  India|     69|\n",
      "+-------------+-------+-------+\n",
      "only showing top 3 rows\n",
      "\n",
      "+-----------------+-------------+-------+\n",
      "|             DEST|       ORIGIN|FLIGHTS|\n",
      "+-----------------+-------------+-------+\n",
      "|    United States|      Romania|      1|\n",
      "|    United States|      Ireland|    264|\n",
      "|    United States|        India|     69|\n",
      "|            Egypt|United States|     24|\n",
      "|Equatorial Guinea|United States|      1|\n",
      "+-----------------+-------------+-------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.selectExpr(\"DEST_COUNTRY_NAME AS DEST\", \"ORIGIN_COUNTRY_NAME AS ORIGIN\", \"count AS FLIGHTS\").show(3)\n",
    "\n",
    "df\\\n",
    "    .withColumnRenamed(\"DEST_COUNTRY_NAME\", \"DEST\")\\\n",
    "    .withColumnRenamed(\"ORIGIN_COUNTRY_NAME\", \"ORIGIN\")\\\n",
    "    .withColumnRenamed(\"count\", \"FLIGHTS\")\\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If a column name has spaces or reserverd keywords use backticks \\`colum name-with reserved+characters\\`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ParseException",
     "evalue": "\nPossibly unquoted identifier of-flights detected. Please consider quoting it with back-quotes as `of-flights`(line 1, pos 10)\n\n== SQL ==\nNumber of -flights-\n----------^^^\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mParseException\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-2c6421670a41>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwithColumnRenamed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"count\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"Number of -flights-\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;31m\\\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;34m.\u001b[0m\u001b[0mselectExpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Number of -flights-\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# This will fail\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/dataframe.py\u001b[0m in \u001b[0;36mselectExpr\u001b[0;34m(self, *expr)\u001b[0m\n\u001b[1;32m   1433\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1434\u001b[0m             \u001b[0mexpr\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexpr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1435\u001b[0;31m         \u001b[0mjdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mselectExpr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_jseq\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mexpr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1436\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjdf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msql_ctx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/lib/py4j-0.10.9-src.zip/py4j/java_gateway.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args)\u001b[0m\n\u001b[1;32m   1302\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1303\u001b[0m         \u001b[0manswer\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgateway_client\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1304\u001b[0;31m         return_value = get_return_value(\n\u001b[0m\u001b[1;32m   1305\u001b[0m             answer, self.gateway_client, self.target_id, self.name)\n\u001b[1;32m   1306\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mdeco\u001b[0;34m(*a, **kw)\u001b[0m\n\u001b[1;32m    135\u001b[0m                 \u001b[0;31m# Hide where the exception came from that shows a non-Pythonic\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    136\u001b[0m                 \u001b[0;31m# JVM exception message.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 137\u001b[0;31m                 \u001b[0mraise_from\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconverted\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    138\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    139\u001b[0m                 \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/spark/python/pyspark/sql/utils.py\u001b[0m in \u001b[0;36mraise_from\u001b[0;34m(e)\u001b[0m\n",
      "\u001b[0;31mParseException\u001b[0m: \nPossibly unquoted identifier of-flights detected. Please consider quoting it with back-quotes as `of-flights`(line 1, pos 10)\n\n== SQL ==\nNumber of -flights-\n----------^^^\n"
     ]
    }
   ],
   "source": [
    "df.withColumnRenamed(\"count\", \"Number of -flights-\")\\\n",
    "    .selectExpr(\"Number of -flights-\") # This will fail"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[Number of -flights-: int]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.withColumnRenamed(\"count\", \"Number of -flights-\")\\\n",
    "    .selectExpr(\"`Number of -flights-`\") # This won't fail because backtics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+\n",
      "|   dest_country_name|\n",
      "+--------------------+\n",
      "|       United States|\n",
      "|       United States|\n",
      "|       United States|\n",
      "|               Egypt|\n",
      "|   Equatorial Guinea|\n",
      "|       United States|\n",
      "|       United States|\n",
      "|          Costa Rica|\n",
      "|             Senegal|\n",
      "|       United States|\n",
      "|              Guyana|\n",
      "|       United States|\n",
      "|               Malta|\n",
      "|             Bolivia|\n",
      "|            Anguilla|\n",
      "|Turks and Caicos ...|\n",
      "|       United States|\n",
      "|Saint Vincent and...|\n",
      "|               Italy|\n",
      "|       United States|\n",
      "+--------------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"dest_country_name\").show()  # Case insensitive unless specified with "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Removing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[DEST_COUNTRY_NAME: string, ORIGIN_COUNTRY_NAME: string, count: int]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|DEST_COUNTRY_NAME|count|\n",
      "+-----------------+-----+\n",
      "|    United States|    1|\n",
      "+-----------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"DEST_COUNTRY_NAME\", \"count\").show(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-----+\n",
      "|DEST_COUNTRY_NAME|count|\n",
      "+-----------------+-----+\n",
      "|    United States|    1|\n",
      "+-----------------+-----+\n",
      "only showing top 1 row\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Same as:\n",
    "df.drop(\"ORIGIN_COUNTRY_NAME\").show(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Casting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+------------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|count(float)|\n",
      "+-----------------+-------------------+-----+------------+\n",
      "|    United States|            Romania|    1|         1.0|\n",
      "|    United States|            Ireland|  264|       264.0|\n",
      "|    United States|              India|   69|        69.0|\n",
      "|            Egypt|      United States|   24|        24.0|\n",
      "|Equatorial Guinea|      United States|    1|         1.0|\n",
      "+-----------------+-------------------+-----+------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.withColumn(\"count(float)\", F.col(\"count\").cast(\"float\")).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    ".where() and .filter() are the same "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|            Romania|    1|\n",
      "|   Equatorial Guinea|      United States|    1|\n",
      "|               Malta|      United States|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|            Slovakia|      United States|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(F.col(\"count\") < 2).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because of spark optimizations, it's better to chain filters instead of using ANDs inside 1 filter "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|   Equatorial Guinea|      United States|    1|\n",
      "|               Malta|      United States|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|            Slovakia|      United States|    1|\n",
      "|       United States|             Cyprus|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter((F.col(\"count\") < 2) & (F.col(\"ORIGIN_COUNTRY_NAME\") != \"Romania\")).show(5)  # This works but its better to let Spark optimize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|   Equatorial Guinea|      United States|    1|\n",
      "|               Malta|      United States|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|            Slovakia|      United States|    1|\n",
      "|       United States|             Cyprus|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.filter(F.col(\"count\") < 2)\\\n",
    "    .filter(F.col(\"ORIGIN_COUNTRY_NAME\") != \"Romania\")\\\n",
    "    .show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Distinct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+\n",
      "|ORIGIN_COUNTRY_NAME|\n",
      "+-------------------+\n",
      "|             Russia|\n",
      "|           Anguilla|\n",
      "|           Paraguay|\n",
      "|            Senegal|\n",
      "|             Sweden|\n",
      "+-------------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.select(\"ORIGIN_COUNTRY_NAME\").distinct().show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-------------------+-----------------+\n",
      "|ORIGIN_COUNTRY_NAME|DEST_COUNTRY_NAME|\n",
      "+-------------------+-----------------+\n",
      "|       Saint Martin|    United States|\n",
      "|             Guinea|    United States|\n",
      "|            Romania|    United States|\n",
      "|            Croatia|    United States|\n",
      "|            Ireland|    United States|\n",
      "+-------------------+-----------------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Or a combination by \n",
    "df.select(\"ORIGIN_COUNTRY_NAME\", \"DEST_COUNTRY_NAME\").distinct().show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Split of Dataframes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Sampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+--------------------+-----+\n",
      "|DEST_COUNTRY_NAME| ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+--------------------+-----+\n",
      "|       Costa Rica|       United States|  477|\n",
      "|    United States|         Afghanistan|    2|\n",
      "|            Italy|       United States|  390|\n",
      "|         Colombia|       United States|  785|\n",
      "|    United States|               Palau|   30|\n",
      "|    United States|             Finland|   20|\n",
      "|    United States|              Greece|   61|\n",
      "|    United States|           Hong Kong|  293|\n",
      "|    United States|               Egypt|   25|\n",
      "|    United States|              Turkey|   87|\n",
      "|    United States|             Estonia|    1|\n",
      "|    United States|            Thailand|   13|\n",
      "|    United States|Turks and Caicos ...|  147|\n",
      "|           Cyprus|       United States|    2|\n",
      "|            Qatar|       United States|   41|\n",
      "|    United States|Saint Vincent and...|   16|\n",
      "|            Aruba|       United States|  359|\n",
      "|        Singapore|       United States|   25|\n",
      "|    United States|              Sweden|   73|\n",
      "|    United States|             Denmark|  107|\n",
      "+-----------------+--------------------+-----+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "seed = 42\n",
    "withReplacement = False\n",
    "fraction = 0.1\n",
    "df.sample(withReplacement, fraction, seed).show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_dataframes = df.randomSplit([0.25, 0.75], seed=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First DF Count: 368\n",
      "Second DF Count: 1134\n"
     ]
    }
   ],
   "source": [
    "print(f\"First DF Count: {split_dataframes[0].count()}\")\n",
    "print(f\"Second DF Count: {split_dataframes[1].count()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train test split for Machine Learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train, test = df.randomSplit([0.75, 0.25], seed=101)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1097"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "405"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Concat and Append"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unions are based on location and not schema, so be careful"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark.sql import Row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "schema = df.schema"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "newRows = [\n",
    "    Row(\"New Country\", \"Other Country\", 5),\n",
    "    Row(\"New Country 2\", \"Other Country 3\", 3)\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "parallelizedRows = spark.sparkContext.parallelize(newRows)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "newDF = spark.createDataFrame(parallelizedRows, schema=schema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|      New Country|      Other Country|    5|\n",
      "|    New Country 2|    Other Country 3|    3|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "newDF.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|    French Guiana|      United States|    5|\n",
      "|           Guinea|      United States|    5|\n",
      "|      Afghanistan|      United States|    5|\n",
      "|      New Country|      Other Country|    5|\n",
      "+-----------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.union(newDF)\\\n",
    "    .filter(\"count = 5\")\\\n",
    "    .filter(\"DEST_COUNTRY_NAME != 'United States'\")\\\n",
    "    .show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sorting Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|       United States|               Mali|    1|\n",
      "|Saint Helena, Asc...|      United States|    1|\n",
      "|       United States|           Malaysia|    1|\n",
      "|       United States|              Niger|    1|\n",
      "|             Burundi|      United States|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(\"count\").show(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+-----+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+-----------------+-------------------+-----+\n",
      "|       Azerbaijan|      United States|    1|\n",
      "|          Belarus|      United States|    1|\n",
      "|          Belarus|      United States|    1|\n",
      "|           Brunei|      United States|    1|\n",
      "|         Bulgaria|      United States|    1|\n",
      "+-----------------+-------------------+-----+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sort(\"count\", \"DEST_COUNTRY_NAME\").show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ascending or Descending Order"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3 Different ways to do it!  \n",
    "F.desc(), F.col(\"x\").desc() and F.expr(\"col desc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n",
      "+-----------------+-------------------+------+\n",
      "|    United States|      United States|370002|\n",
      "|    United States|      United States|358354|\n",
      "|    United States|      United States|352742|\n",
      "|    United States|      United States|348113|\n",
      "|    United States|      United States|347452|\n",
      "|    United States|      United States|343132|\n",
      "|    United States|             Canada|  8650|\n",
      "|           Canada|      United States|  8514|\n",
      "|    United States|             Canada|  8483|\n",
      "|           Canada|      United States|  8399|\n",
      "|    United States|             Canada|  8305|\n",
      "|           Canada|      United States|  8271|\n",
      "|    United States|             Canada|  8177|\n",
      "|    United States|             Canada|  8097|\n",
      "|           Canada|      United States|  8034|\n",
      "|    United States|             Canada|  7983|\n",
      "|           Canada|      United States|  7974|\n",
      "|           Canada|      United States|  7860|\n",
      "|    United States|             Mexico|  7187|\n",
      "|           Mexico|      United States|  7140|\n",
      "+-----------------+-------------------+------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(F.desc(\"count\"), F.col(\"DEST_COUNTRY_NAME\").asc(), F.expr(\"ORIGIN_COUNTRY_NAME desc\")).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For optimization purposes, sometimes it's better to sort within Partitions before doing more transofrmations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+-----------------+-------------------+------+\n",
      "|DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME| count|\n",
      "+-----------------+-------------------+------+\n",
      "|    United States|      United States|370002|\n",
      "|    United States|      United States|352742|\n",
      "|    United States|      United States|348113|\n",
      "|    United States|             Canada|  8650|\n",
      "|           Canada|      United States|  8514|\n",
      "+-----------------+-------------------+------+\n",
      "only showing top 5 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.sortWithinPartitions(F.col(\"count\").desc_nulls_first()).show(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Limit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------------+-------------------+-----+\n",
      "|   DEST_COUNTRY_NAME|ORIGIN_COUNTRY_NAME|count|\n",
      "+--------------------+-------------------+-----+\n",
      "|            Malaysia|      United States|    1|\n",
      "|       United States|            Algeria|    1|\n",
      "|       United States|            Romania|    1|\n",
      "|          Azerbaijan|      United States|    1|\n",
      "|               Malta|      United States|    1|\n",
      "|             Liberia|      United States|    1|\n",
      "|Saint Vincent and...|      United States|    1|\n",
      "|       United States|            Vietnam|    1|\n",
      "|            Slovakia|      United States|    1|\n",
      "|       United States|            Estonia|    1|\n",
      "+--------------------+-------------------+-----+\n",
      "\n"
     ]
    }
   ],
   "source": [
    "df.orderBy(F.expr(\"count DESC\")).limit(10).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Repartition and Coalesce"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Partition calls a full shuffle, so do it only if partitions needs to increase ex:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "part_df = df.repartition(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "part_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can also repartition based on a specific column if you're going to filter by it a lot:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "dest_df = df.repartition(F.col(\"DEST_COUNTRY_NAME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "200"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dest_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can also repartition by a column and set a number of partitions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "small_dest_df = df.repartition(10, F.col(\"DEST_COUNTRY_NAME\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "10"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "small_dest_df.rdd.getNumPartitions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Collect to Driver"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you colllect/take data, its passed to the driver (make sure driver is big enough for the data collected)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "collectDF = df\\\n",
    "    .filter(\"DEST_COUNTRY_NAME != 'United States'\")\\\n",
    "    .filter(\"count > 1\")\\\n",
    "    .filter(\"count < 1000\")\\\n",
    "    .orderBy(F.col(\"count\").desc_nulls_last())\\\n",
    "    .limit(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Row(DEST_COUNTRY_NAME='Brazil', ORIGIN_COUNTRY_NAME='United States', count=995),\n",
       " Row(DEST_COUNTRY_NAME='Brazil', ORIGIN_COUNTRY_NAME='United States', count=979),\n",
       " Row(DEST_COUNTRY_NAME='The Bahamas', ORIGIN_COUNTRY_NAME='United States', count=975),\n",
       " Row(DEST_COUNTRY_NAME='Brazil', ORIGIN_COUNTRY_NAME='United States', count=969),\n",
       " Row(DEST_COUNTRY_NAME='South Korea', ORIGIN_COUNTRY_NAME='United States', count=968),\n",
       " Row(DEST_COUNTRY_NAME='France', ORIGIN_COUNTRY_NAME='United States', count=966),\n",
       " Row(DEST_COUNTRY_NAME='The Bahamas', ORIGIN_COUNTRY_NAME='United States', count=955),\n",
       " Row(DEST_COUNTRY_NAME='The Bahamas', ORIGIN_COUNTRY_NAME='United States', count=950),\n",
       " Row(DEST_COUNTRY_NAME='France', ORIGIN_COUNTRY_NAME='United States', count=935),\n",
       " Row(DEST_COUNTRY_NAME='Brazil', ORIGIN_COUNTRY_NAME='United States', count=927)]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "collectDF.collect()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* There is another way of collecting by partition using .toLocalIterator() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_local = df.repartition(F.col(\"DEST_COUNTRY_NAME\")).limit(10).toLocalIterator()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object _local_iterator_from_socket.<locals>.PyLocalIterable.__iter__ at 0x7fc0108ffb30>"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "my_local  # Is a generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Row(DEST_COUNTRY_NAME='Chad', ORIGIN_COUNTRY_NAME='United States', count=1)\n",
      "Row(DEST_COUNTRY_NAME='Anguilla', ORIGIN_COUNTRY_NAME='United States', count=21)\n",
      "Row(DEST_COUNTRY_NAME='Russia', ORIGIN_COUNTRY_NAME='United States', count=152)\n",
      "Row(DEST_COUNTRY_NAME='Paraguay', ORIGIN_COUNTRY_NAME='United States', count=90)\n",
      "Row(DEST_COUNTRY_NAME='Anguilla', ORIGIN_COUNTRY_NAME='United States', count=41)\n",
      "Row(DEST_COUNTRY_NAME='Russia', ORIGIN_COUNTRY_NAME='United States', count=176)\n",
      "Row(DEST_COUNTRY_NAME='Paraguay', ORIGIN_COUNTRY_NAME='United States', count=60)\n",
      "Row(DEST_COUNTRY_NAME='Anguilla', ORIGIN_COUNTRY_NAME='United States', count=21)\n",
      "Row(DEST_COUNTRY_NAME='Russia', ORIGIN_COUNTRY_NAME='United States', count=199)\n",
      "Row(DEST_COUNTRY_NAME='Paraguay', ORIGIN_COUNTRY_NAME='United States', count=85)\n"
     ]
    }
   ],
   "source": [
    "for item in my_test:\n",
    "    print(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "toc-autonumbering": true,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false,
  "toc-showtags": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
